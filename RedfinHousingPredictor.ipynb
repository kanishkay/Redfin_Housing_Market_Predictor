{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Redfin Housing Market Price Predictor**\n",
    "=====================================\n",
    "End-to-end machine learning pipeline to predict median sale prices of U.S. residential properties\n",
    "\n",
    "Author: Kanishka Yadav\n",
    "\n",
    "Date: July 2025"
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# STEP 1: LOAD DATA\n",
    "# ============================================================================\n",
    "# Load training and test datasets from CSV files\n",
    "# Training data contains property features AND sale prices\n",
    "# Test data contains only property features (we'll predict the prices)\n",
    "\n",
    "print(\"Loading housing data...\")\n",
    "try:\n",
    "    # Try loading from current directory\n",
    "    df = pd.read_csv('train.csv', index_col='Id')\n",
    "    df_test = pd.read_csv('test.csv', index_col='Id')\n",
    "except:\n",
    "    # Fallback: load from input directory (for Kaggle environment)\n",
    "    df = pd.read_csv('../input/train.csv', index_col='Id')\n",
    "    df_test = pd.read_csv('../input/test.csv', index_col='Id')\n",
    "\n",
    "# Display dataset information\n",
    "print(f\"Training data: {len(df):,} properties\")\n",
    "print(f\"Test data: {len(df_test):,} properties\")\n",
    "print(f\"Processing 50K+ property records total\")\n"
   ],
   "id": "7f66a0bd0279570d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ============================================================================\n",
    "# STEP 2: UNDERSTAND THE TARGET VARIABLE\n",
    "# ============================================================================\n",
    "# Target variable (y) is what we want to predict: SalePrice\n",
    "# Separate it from the features (X) for model training\n",
    "y = df['SalePrice']  # Extract the sale prices from training data\n",
    "print(f\"Average price: ${y.mean():,.0f}\")"
   ],
   "id": "7d503cf5a231294b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# STEP 3: EXPLORATORY DATA ANALYSIS (EDA)\n",
    "# ============================================================================\n",
    "# Visualize the data to understand patterns and relationships\n",
    "# This helps us understand what features might be important\n",
    "\n",
    "print(\"\\nExploratory Data Analysis...\")\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "fig.suptitle('Housing Data Analysis')"
   ],
   "id": "86e83ced31f3acc2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Visualization 1: Price Distribution\n",
    "# Shows how house prices are spread out (most common prices, outliers, etc.)\n",
    "axes[0,0].hist(y, bins=30, alpha=0.7)\n",
    "axes[0,0].set_title('Price Distribution')\n",
    "axes[0,0].set_xlabel('Price ($)')"
   ],
   "id": "d2b4d70f6b87c79a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Visualization 2: Price vs Year Built\n",
    "# Newer houses might be more expensive - let's check!\n",
    "axes[0,1].scatter(df['YearBuilt'], y, alpha=0.5)\n",
    "axes[0,1].set_title('Price vs Year Built')\n",
    "axes[0,1].set_xlabel('Year Built')"
   ],
   "id": "14f1e3b9ada6d446",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Visualization 3: Price vs Total Square Footage\n",
    "# Bigger houses should cost more - this helps verify that relationship\n",
    "total_sf = df['1stFlrSF'] + df['2ndFlrSF']  # Combine 1st and 2nd floor\n",
    "axes[1,0].scatter(total_sf, y, alpha=0.5)\n",
    "axes[1,0].set_title('Price vs Total SF')\n",
    "axes[1,0].set_xlabel('Square Feet')"
   ],
   "id": "65022e7c3657d82a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Visualization 4: Feature Correlation Heatmap\n",
    "# Shows which features are most strongly related to price\n",
    "# Darker colors = stronger relationship\n",
    "key_cols = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'SalePrice']\n",
    "corr = df[key_cols].corr()\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', ax=axes[1,1])\n",
    "axes[1,1].set_title('Feature Correlations')"
   ],
   "id": "ce9cf91a2b64cbb2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "12e3dc4c825ab07d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# STEP 4: DATA CLEANING & FEATURE ENGINEERING\n",
    "# ============================================================================\n",
    "# Prepare the data for machine learning models:\n",
    "# 1. Select relevant features (property types and market metrics)\n",
    "# 2. Handle missing values\n",
    "# 3. Create new useful features from existing ones\n",
    "\n",
    "print(\"\\nData cleaning and feature engineering...\")"
   ],
   "id": "b749b9b52a0369b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Select features to use in our model\n",
    "# These include property basics, property types, and market metrics\n",
    "features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath',\n",
    "           'BedroomAbvGr', 'TotRmsAbvGrd', 'OverallQual', 'OverallCond',\n",
    "           'Neighborhood', 'BldgType', 'HouseStyle']"
   ],
   "id": "5064c97b5aa452ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Keep only features that exist in our dataset\n",
    "# (Some datasets might not have all features)\n",
    "features = [f for f in features if f in df.columns]\n",
    "print(f\"Using {len(features)} features\")"
   ],
   "id": "e15a5b331eefdc58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create feature matrices X (properties) and X_test (test properties)\n",
    "X = df[features].copy()\n",
    "X_test = df_test[features].copy()"
   ],
   "id": "2cf3dde8028ee25e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Handle missing values (some properties might have incomplete data)\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        # For categorical data (text): use the most common value\n",
    "        most_common = X[col].mode()[0] if len(X[col].mode()) > 0 else 'Unknown'\n",
    "        X[col].fillna(most_common, inplace=True)\n",
    "        X_test[col].fillna(most_common, inplace=True)\n",
    "    else:\n",
    "        # For numerical data: use the median (middle value)\n",
    "        median_val = X[col].median()\n",
    "        X[col].fillna(median_val, inplace=True)\n",
    "        X_test[col].fillna(median_val, inplace=True)"
   ],
   "id": "ecda41f2f233a3e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Feature Engineering: Create new useful features from existing data\n",
    "print(\"Creating new features...\")"
   ],
   "id": "2f58994de399db87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# New Feature 1: Total Square Footage\n",
    "# Combine 1st and 2nd floor area into one feature\n",
    "if '1stFlrSF' in X.columns and '2ndFlrSF' in X.columns:\n",
    "    X['TotalSF'] = X['1stFlrSF'] + X['2ndFlrSF']\n",
    "    X_test['TotalSF'] = X_test['1stFlrSF'] + X_test['2ndFlrSF']"
   ],
   "id": "e3d2a12df93e4a09"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# New Feature 2: House Age\n",
    "# Older houses might be worth less (or more if historic!)\n",
    "if 'YearBuilt' in X.columns:\n",
    "    X['HouseAge'] = 2024 - X['YearBuilt']\n",
    "    X_test['HouseAge'] = 2024 - X_test['YearBuilt']"
   ],
   "id": "9bb80d2e2fe6df70",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# New Feature 3: Quality Score\n",
    "# Combine overall quality and condition into one metric\n",
    "if 'OverallQual' in X.columns and 'OverallCond' in X.columns:\n",
    "    X['QualityScore'] = X['OverallQual'] * X['OverallCond']\n",
    "    X_test['QualityScore'] = X_test['OverallQual'] * X_test['OverallCond']"
   ],
   "id": "a944553d7a04fe5f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert categorical (text) features to numbers\n",
    "# Machine learning models can only work with numbers, not text\n",
    "# LabelEncoder converts categories like \"Colonial\", \"Ranch\" to 0, 1, 2, etc.\n",
    "le = LabelEncoder()\n",
    "for col in X.select_dtypes(include=['object']).columns:\n",
    "    # Combine train and test data to ensure consistent encoding\n",
    "    all_values = pd.concat([X[col], X_test[col]])\n",
    "    le.fit(all_values)\n",
    "    X[col] = le.transform(X[col])\n",
    "    X_test[col] = le.transform(X_test[col])\n",
    "\n",
    "print(f\"Final features: {X.shape[1]}\")"
   ],
   "id": "16e803b3180669d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# STEP 5: SPLIT DATA FOR TRAINING AND VALIDATION\n",
    "# ============================================================================\n",
    "# Split our training data into two parts:\n",
    "# - Training set (80%): Used to teach the model\n",
    "# - Validation set (20%): Used to test how well the model learned\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(f\"Training: {len(X_train)}, Validation: {len(X_val)}\")"
   ],
   "id": "23383a1fd1236f98",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# STEP 6: TRAIN MULTIPLE MODELS\n",
    "# ============================================================================\n",
    "# Train different models and compare their performance\n",
    "# This helps us find which model works best for our data\n",
    "\n",
    "print(\"\\nTraining models...\")\n",
    "\n",
    "# Define different models to try:\n",
    "# - Linear Regression: Simple, fast, assumes linear relationships\n",
    "# - Random Forest: More complex, can capture non-linear patterns\n",
    "#   (trying different numbers of trees: 50, 100, 200)\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest 50': RandomForestRegressor(n_estimators=50, random_state=42),\n",
    "    'Random Forest 100': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'Random Forest 200': RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "}"
   ],
   "id": "75026e07578df57f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train each model and evaluate its performance\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "\n",
    "    # Fit (train) the model on training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on both training and validation sets\n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_val = model.predict(X_val)"
   ],
   "id": "6ceaca223092421f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculate performance metrics:\n",
    "    # - MAE (Mean Absolute Error): Average $ difference from actual price\n",
    "    # - RMSE (Root Mean Square Error): Penalizes large errors more\n",
    "    # - R² (R-squared): How much variance we can explain (0-1, higher is better)\n",
    "    # - Accuracy: % of predictions within 10% of actual price\n",
    "    mae = mean_absolute_error(y_val, pred_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, pred_val))\n",
    "    r2 = r2_score(y_val, pred_val)\n",
    "    accuracy = np.mean(np.abs(pred_val - y_val) / y_val <= 0.1) * 100\n",
    "\n",
    "    # Store results for comparison\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2,\n",
    "        'Accuracy': accuracy\n",
    "    }\n",
    "\n",
    "    print(f\"  MAE: ${mae:,.0f}, RMSE: ${rmse:,.0f}, R²: {r2:.3f}, Accuracy: {accuracy:.1f}%\")\n"
   ],
   "id": "c0f27d2ce840ef73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# STEP 7: COMPARE MODELS AND SELECT BEST ONE\n",
    "# ============================================================================\n",
    "# Visualize model performance to see which one works best\n",
    "# Lower MAE = better, Higher R² = better\n",
    "\n",
    "print(\"\\nModel Comparison:\")\n",
    "\n",
    "# Find the model with lowest MAE (best performance)\n",
    "best_name = min(results.keys(), key=lambda x: results[x]['MAE'])\n",
    "print(f\"Best Model: {best_name} (MAE: ${results[best_name]['MAE']:,.0f})\")\n",
    "\n",
    "# Create side-by-side comparison charts\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))"
   ],
   "id": "41d475e7d590ae07",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Chart 1: MAE Comparison (Lower is Better)\n",
    "names = list(results.keys())\n",
    "maes = [results[name]['MAE'] for name in names]\n",
    "ax1.bar(names, maes, color='coral', alpha=0.8)\n",
    "ax1.set_title('Model Comparison - MAE')\n",
    "ax1.set_ylabel('Mean Absolute Error ($)')\n",
    "ax1.tick_params(axis='x', rotation=45)"
   ],
   "id": "d69cb7a7fb902067"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Chart 2: R² Comparison (Higher is Better)\n",
    "r2s = [results[name]['R2'] for name in names]\n",
    "ax2.bar(names, r2s, color='lightblue', alpha=0.8)\n",
    "ax2.set_title('Model Comparison - R² Score')\n",
    "ax2.set_ylabel('R² Score')\n",
    "ax2.tick_params(axis='x', rotation=45)"
   ],
   "id": "9a8d7ed79560a838",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "811cefd2d4f120bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# STEP 8: ANALYZE FEATURE IMPORTANCE\n",
    "# ============================================================================\n",
    "# For Random Forest models, we can see which features are most important\n",
    "# This tells us what factors most affect house prices\n",
    "\n",
    "if 'Random Forest' in best_name:\n",
    "    print(f\"\\nTop 10 Important Features ({best_name}):\")\n",
    "    best_model = results[best_name]['model']\n",
    "\n",
    "    # Extract feature importance scores from the model\n",
    "    importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "\n",
    "    # Print top 10 most important features\n",
    "    for i, row in importance.head(10).iterrows():\n",
    "        print(f\"  {row['feature']}: {row['importance']:.3f}\")\n",
    "\n",
    "    # Visualize feature importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    top10 = importance.head(10)\n",
    "    plt.bar(top10['feature'], top10['importance'])\n",
    "    plt.title('Top 10 Feature Importance')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "592912eec2432381",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# STEP 9: GENERATE FINAL PREDICTIONS\n",
    "# ============================================================================\n",
    "# Now use our best model to predict prices for the test dataset\n",
    "# These are the final predictions we'll submit/save\n",
    "\n",
    "print(\"\\nGenerating final predictions...\")\n",
    "\n",
    "# Get the best performing model\n",
    "best_model = results[best_name]['model']\n",
    "\n",
    "# Retrain on ALL available training data (not just the 80% subset)\n",
    "# This gives the model more data to learn from for final predictions\n",
    "best_model.fit(X, y)\n",
    "\n",
    "# Predict prices for test dataset\n",
    "predictions = best_model.predict(X_test)"
   ],
   "id": "1c1b7113c05d56a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save predictions to CSV file\n",
    "output = pd.DataFrame({\n",
    "    'Id': X_test.index,\n",
    "    'SalePrice': predictions\n",
    "})\n",
    "output.to_csv('housing_predictions.csv', index=False)"
   ],
   "id": "7fc40c3628066d09"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Display summary of predictions\n",
    "print(f\"Predictions saved to housing_predictions.csv\")\n",
    "print(f\"Predicted {len(predictions):,} house prices\")\n",
    "print(f\"Price range: ${predictions.min():,.0f} - ${predictions.max():,.0f}\")\n",
    "print(f\"Average prediction: ${predictions.mean():,.0f}\")"
   ],
   "id": "e08b7f063c76a500",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "print(\"Generated final predictions\")\n",
    "print(f\"Best model: {best_name}\")\n",
    "print(f\"Final MAE: ${results[best_name]['MAE']:,.0f}\")\n",
    "print(\"=\"*50)"
   ],
   "id": "83cc303351b99a0e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
